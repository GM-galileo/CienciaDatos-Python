{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brutal-affiliate",
   "metadata": {},
   "source": [
    "# <font color=blue>**PROYECTO** - Modelos Predictivos de Regresión Lineal Uni-Variable Sencillos</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "raising-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aging-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0850e+05 7.0000e+00 8.5600e+02 8.0000e+00 2.0030e+03 6.5000e+01]\n",
      " [1.8150e+05 6.0000e+00 1.2620e+03 6.0000e+00 1.9760e+03 8.0000e+01]\n",
      " [2.2350e+05 7.0000e+00 9.2000e+02 6.0000e+00 2.0010e+03 6.8000e+01]\n",
      " ...\n",
      " [2.4535e+05 8.0000e+00 1.6940e+03 7.0000e+00 2.0080e+03 6.4000e+01]\n",
      " [1.7300e+05 6.0000e+00 9.5900e+02 7.0000e+00 2.0000e+03 5.8000e+01]\n",
      " [2.3500e+05 6.0000e+00 1.2360e+03 7.0000e+00 1.9350e+03 1.2000e+02]]\n",
      "(291, 6)\n"
     ]
    }
   ],
   "source": [
    "#●\tUsando sclicing con NumPy separar los datos en 2 datasets\n",
    "PreciosCasas = np.load('proyecto_training_data.npy')\n",
    "DatosEntrenamiento = PreciosCasas[0:int(PreciosCasas.shape[0]*.8)+1]\n",
    "DatosValidacionPrueba = PreciosCasas[int(PreciosCasas.shape[0]*.8)+1:]\n",
    "#print(DatosEntrenamiento)\n",
    "#print(DatosValidacionPrueba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-japan",
   "metadata": {},
   "source": [
    "## ●\tAnálisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "julian-commission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VARIABLE 1\n",
      "Media               ->35239.833333333336\n",
      "Max                 ->208500.0\n",
      "Min                 ->7.0\n",
      "Rango               ->208493.0\n",
      "Desviacion Estandar ->77487.55164845655\n",
      "VARIABLE 2\n",
      "Media               ->30805.0\n",
      "Max                 ->181500.0\n",
      "Min                 ->6.0\n",
      "Rango               ->181494.0\n",
      "Desviacion Estandar ->67396.91578254898\n",
      "VARIABLE 3\n",
      "Media               ->37750.333333333336\n",
      "Max                 ->223500.0\n",
      "Min                 ->6.0\n",
      "Rango               ->223494.0\n",
      "Desviacion Estandar ->83072.83863106053\n",
      "VARIABLE 4\n",
      "Media               ->23825.0\n",
      "Max                 ->140000.0\n",
      "Min                 ->7.0\n",
      "Rango               ->139993.0\n",
      "Desviacion Estandar ->51959.616841671705\n",
      "VARIABLE 5\n",
      "Media               ->42207.666666666664\n",
      "Max                 ->250000.0\n",
      "Min                 ->8.0\n",
      "Rango               ->249992.0\n",
      "Desviacion Estandar ->92930.43587663959\n",
      "VARIABLE 6\n",
      "Media               ->24314.0\n",
      "Max                 ->143000.0\n",
      "Min                 ->5.0\n",
      "Rango               ->142995.0\n",
      "Desviacion Estandar ->53082.62327730234\n"
     ]
    }
   ],
   "source": [
    "#○\tPara cada variable en el dataset calcular((usando numpy o pandas):\n",
    "#   ■\tmedia\n",
    "#   ■\tvalor máximo\n",
    "#   ■\tvalor mínimo \n",
    "#   ■\trango(peak to peak, no el rango del tensor que por ser vector sabemos que es 1)\n",
    "#   ■\tdesviación estándar \n",
    "\n",
    "for i in range(DatosEntrenamiento.shape[1]):\n",
    "    VarMedia = np.mean(DatosEntrenamiento[i])\n",
    "    VarMax = np.max(DatosEntrenamiento[i])\n",
    "    VarMin = np.min(DatosEntrenamiento[i])\n",
    "    VarPeak = np.ptp(DatosEntrenamiento[i])\n",
    "    VarDesv = np.std(DatosEntrenamiento[i])\n",
    "    \n",
    "    print('VARIABLE '+ str(i+1))\n",
    "    print('Media               ->' + str(VarMedia))\n",
    "    print('Max                 ->' + str(VarMax))\n",
    "    print('Min                 ->' + str(VarMin))\n",
    "    print('Rango               ->' + str(VarPeak))\n",
    "    print('Desviacion Estandar ->' + str(VarDesv))\n",
    "    #info = np.array([VarMedia,VarMax,VarMin,VarPeak,VarDesv]\n",
    "    #AnalisisExploratorio = np.append(AnalisisExploratorio, ),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#○\tPara cada variable en el dataset usar seaborn(función distplot https://seaborn.pydata.org/generated/seaborn.distplot.html)  \n",
    "#para graficar  un histograma de la variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-wonder",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
